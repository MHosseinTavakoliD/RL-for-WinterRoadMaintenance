{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:44:51.983967800Z",
     "start_time": "2024-02-11T15:44:51.932182100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Virtual Environment\n",
    "# All the units are in SI system\n",
    "import numpy as np\n",
    "# \n",
    "\n",
    "# Virtual Environment\n",
    "# All the units are in SI system\n",
    "import numpy as np\n",
    "# \n",
    "\n",
    "def Matrial_on_the_road(Air_temp, Suraface_temp, Precipitation, wind_vel,initial_Snow, initial_water, initial_Salt, initial_ice, plowing):\n",
    "    # General assumptions:\n",
    "    Dataset_hour_inc = 1 # *3 had applied in the dataset\n",
    "    f_t = 0.9 #times when the road is covered with moving vehicle\n",
    "    g_t = 1 - f_t\n",
    "    \n",
    "    \n",
    "    \n",
    "    # convert Precipitation to snow or rain based on the air temp\n",
    "    if Air_temp < .5:\n",
    "        Snowfall_amount = Precipitation\n",
    "        Rainfall_amount = 0\n",
    "    else:\n",
    "        Rainfall_amount = Precipitation\n",
    "        Snowfall_amount = 0\n",
    "    \n",
    "    ###### Heat Ballance ##########################################################################################################\n",
    "    # Q_csp : Flux of pavement heat\n",
    "    V_wis = initial_ice + initial_Snow + Snowfall_amount # Volume of WIS layer (m3*m-2 = m) depth of material on the road\n",
    "    V_ps = 50e-3 # thikness of pavement surface, generally 25 to 55 mm, here we assume 50mm\n",
    "    Lambda_wis = 0.8 # thermal conductivity of WIS layer. Assume that is compacted snow \n",
    "    Lambda_P = 1.5 # Thermal conductivity of pavemetn. 0.8 to 2\n",
    "    T_wis = (Air_temp + Suraface_temp)/2 #Temp of wis layer: assumption \n",
    "    Q_csp = 1/((V_wis/(2*Lambda_wis))+(V_ps/(2*Lambda_P)))*(Suraface_temp - T_wis)\n",
    "    \n",
    "     # Q_rn : Flux of net radient heat\n",
    "    q_rld = 20 #Since we are modeling the winter stroms, the sky radiation shouldn't be high 0-200\n",
    "    q_rlu = 0.97 * 5.64e-8 * (T_wis + 273.15)**4\n",
    "    q_rsd = 20 #Since we are modeling the winter stroms, the sky radiation shouldn't be high 0-300\n",
    "    q_rsu = 0.3 * q_rsd\n",
    "    Q_rn = f_t*q_rld + q_rlu + f_t*q_rsd - q_rsu\n",
    "    \n",
    "    # Q_sn Flux of net radiant heat\n",
    "    q_sa = (10e4 * wind_vel**0.7 +2.2)*(T_wis - Air_temp)#snesable heat flux due to wind\n",
    "    q_sf = (4.184* (initial_water + Rainfall_amount) + 2.108 * (initial_ice  + initial_Snow + Snowfall_amount))# Sensable heat flux due to rainfall and snowfall\n",
    "    q_sr = 0 #Sensible heat flux of drainage due to road gradient assume = 0\n",
    "    q_sv = 4.184 * T_wis * 1000 * 0.5 * 0.005/3600 * 0.15#sensible heat flux of water dispersion due to passing vehicle\n",
    "    Q_sn = q_sa + f_t*q_sf + q_sr + g_t * q_sv\n",
    "    \n",
    "    # Q_ln flux of net latent heat\n",
    "    # m_wi * L_wi is not considered here, we will change the q_net relation with M_wi later\n",
    "    m_il = 0 # sublimation flux\n",
    "    L_i = 2838 #kJkg-1 latent heat of sublimation\n",
    "    m_wl = 0 # flux of evaporation and condensation\n",
    "    L_w = 2260 #kJkg-1 latent heat of evaporation and condensation\n",
    "    m_sl = 3.34e-5 # dissolving flux (0 - 6.67e-5) if salting\n",
    "    L_s = -66.4 # latent heat of dissolution of salt \n",
    "    Q_ln = m_il*L_i + m_wl*L_w + m_sl*L_s\n",
    "    \n",
    "    # Q_vn flux of net vehicle heat\n",
    "    Q_vn = 100 #assumption according to Fujimoto and other citations\n",
    "    \n",
    "    # Q_net\n",
    "    Q_net = Q_csp + Q_rn + Q_sn + Q_ln + Q_vn\n",
    "    #################################################################################################################################\n",
    "    #*******************************************************************************************************************************#\n",
    "    \n",
    "    ## Material creation $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "    # Ice \n",
    "    Ice_final = initial_ice \n",
    "    \n",
    "    # Snowfall \n",
    "    m_snowf = Snowfall_amount * Dataset_hour_inc * 100 # 100 kg/m3\n",
    "    Snow_creat = m_snowf * f_t\n",
    "    Snow_final = Snow_creat + initial_Snow\n",
    "    # plowing  $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "    if plowing == 1:\n",
    "        Snow_final *= 0.1\n",
    "        \n",
    "    # or rainfall\n",
    "    m_wf = Rainfall_amount * Dataset_hour_inc * 1000 # 1000 kg/m3\n",
    "    Rain_creat = m_wf * f_t\n",
    "    Water_final = Rain_creat + initial_water\n",
    "    # before mesuring the water to ice, we have to consider the water dispersion\n",
    "    # Water dispersion\n",
    "    # Assume we have good drainage system\n",
    "    Water_final = Water_final * 0.95\n",
    "    \n",
    "    #Salt\n",
    "    # Salt_final = initial_Salt * 0.5# Maybe need conversion\n",
    "    \n",
    "    ### Material Conversion $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "    ## Snow to ice\n",
    "    Snow_To_Ice_rate = 0.1 # Assumption: conversion applied to initial snow \n",
    "    Ice_final += Snow_To_Ice_rate * initial_Snow\n",
    "    \n",
    "    ## water to ice or vise versa *\n",
    "    L_wi = 334 #kJkg-1 latent heat of melting and freezing\n",
    "    Water_ice_conv_mass = abs(Q_net/(L_wi*999))\n",
    "    # We will assume that the water freezing point is just a function of salt concentration\n",
    "    T_frezzing = -0.025 * initial_Salt - 0.5\n",
    "    # print(\"TF\",T_frezzing)\n",
    "    \n",
    "    if T_wis > T_frezzing:\n",
    "        STATUS = \"Melting\"\n",
    "        # print(\"###############################Melting\")  # Melting\n",
    "        stat_sign = 1\n",
    "        Ice_final = Ice_final - min(Water_ice_conv_mass, Ice_final)  \n",
    "        Water_final = Water_final + min(Water_ice_conv_mass, Ice_final) \n",
    "    else:\n",
    "        STATUS = \"Freezing\"\n",
    "        # print(\"###############################Freezing\")  # Freezing\n",
    "        Ice_final = Ice_final + min(Water_ice_conv_mass, Water_final)  \n",
    "        Water_final = Water_final - min(Water_ice_conv_mass, Water_final) \n",
    "    \n",
    "\n",
    "    # Snow to water\n",
    "    if STATUS == \"Melting\":\n",
    "        Water_final = Water_final + stat_sign * Water_ice_conv_mass\n",
    "        Water_final = Water_final * 0.05 #disperssed\n",
    "        Snow_final = Snow_final - stat_sign * Water_ice_conv_mass\n",
    "        # print (\"Water_ice_conv_mass\", Water_ice_conv_mass)\n",
    "    ## Material dispersion $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
    "    # Salt dispersion: depands on STATUS\n",
    "    if STATUS == \"Melting\":\n",
    "        Salt_disp_rate = 0.3\n",
    "    if STATUS == \"Freezing\":\n",
    "        Salt_disp_rate = 0.9\n",
    "    Salt_final = initial_Salt * Salt_disp_rate\n",
    "    \n",
    "    \n",
    "    # Check each variable and set to zero if negative\n",
    "    Water_final = max(Water_final, 0)\n",
    "    Salt_final = max(Salt_final, 0)\n",
    "    Ice_final = max(Ice_final, 0)\n",
    "    Snow_final = max(Snow_final, 0)\n",
    "    \n",
    "    \n",
    "    # print (\"Water_final, Salt_final, Ice_final, Snow_final\", Water_final, Salt_final, Ice_final, Snow_final)\n",
    "    return Water_final, Salt_final, Ice_final, Snow_final\n",
    "print (\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, model_path=None):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.1\n",
    "        if model_path:\n",
    "            self.model = load_model(model_path)\n",
    "            print(\"Model loaded from\", model_path)\n",
    "        else:\n",
    "            self.model = self._build_model()\n",
    "            print(\"New model initialized\")\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=total_state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # Biased action selection\n",
    "            actions_probability = [0.25, 0.25, 0.25, 0.25]  # Example: 70% do nothing, 10% for each other action\n",
    "            return np.random.choice(np.arange(self.action_size), p=actions_probability)\n",
    "        else:\n",
    "            act_values = self.model.predict(state)\n",
    "            return np.argmax(act_values[0])\n",
    "    \n",
    "    def predict_action(self, state):\n",
    "        \"\"\"Selects the action with the highest Q-value for the given state.\"\"\"\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "            \n",
    "print (\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:44:52.048363800Z",
     "start_time": "2024-02-11T15:44:51.991141200Z"
    }
   },
   "id": "b3adcae5ccd086c5",
   "execution_count": 314
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class RoadEnv:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.current_state = None\n",
    "        self.action_costs = {0: 0, 1: 1, 2: 6, 3: 5}\n",
    "        self.reset()\n",
    "    def simulate_no_intervention(self, window_data):\n",
    "        no_intervention_results = []\n",
    "        initial_conditions = {'initial_Snow': 0, 'initial_water': 0, 'initial_Salt': 0, 'initial_ice': 0, 'plowing':0}\n",
    "        for index, row in window_data.iterrows():\n",
    "            # Simulate step without interventions\n",
    "            Air_temp = row['Air TemperatureC']\n",
    "            Surface_temp = row['Surface TemperatureC']\n",
    "            Precipitation = row['Precipitation Intensitym/3h'] \n",
    "            wind_vel = row['Wind Speed (act)m/s']\n",
    "            water, salt, ice, snow = Matrial_on_the_road(Air_temp, Surface_temp, Precipitation, wind_vel, **initial_conditions)\n",
    "            # print (\"water, salt, ice, snow\", water, salt, ice, snow)\n",
    "            # Update initial conditions for the next step\n",
    "            initial_conditions.update({'initial_Snow': snow, 'initial_ice': ice, 'initial_water': water, 'initial_Salt': salt, 'plowing': 0})\n",
    "            \n",
    "            # Append results for no intervention forecast\n",
    "            no_intervention_results.append((water, salt, ice, snow))\n",
    "            # print(\"no_intervention_results\",no_intervention_results)\n",
    "        return no_intervention_results\n",
    "    # def reset(self):\n",
    "    #     # Reset the environment to the initial state of a new episode\n",
    "    #     self.current_state = self.dataset.iloc[0].copy()\n",
    "    #     self.plowing_count = 0\n",
    "    #     self.salting_count = 0\n",
    "    #     \n",
    "    #     return self._get_state()\n",
    "    def reset(self, episode_index=0):\n",
    "        # Calculate the start index of the episode in the dataset\n",
    "        start_index = episode_index * 10  # Assuming each episode has 10 states\n",
    "        \n",
    "        # Check if the calculated start index is within the bounds of the dataset\n",
    "        if start_index >= 0 and start_index < len(self.dataset):\n",
    "            self.current_state = self.dataset.iloc[start_index].copy()\n",
    "        else:\n",
    "            # Fallback to the first row if the calculated index is out of bounds\n",
    "            self.current_state = self.dataset.iloc[0].copy()\n",
    "            print(f\"Warning: Episode index {episode_index} out of bounds, falling back to initial state.\")\n",
    "    \n",
    "        # Reset the action counts for the new episode\n",
    "        self.plowing_count = 0\n",
    "        self.salting_count = 0\n",
    "        \n",
    "        # Reset environment to the start of a new episode, with modifications to include no intervention forecast\n",
    "        window_id = unique_window_ids[episode_index]\n",
    "        episode_data = self.dataset[self.dataset['Window_ID'] == window_id]\n",
    "        self.no_intervention_forecast = self.simulate_no_intervention(episode_data)\n",
    "        # print (\"self.no_intervention_forecast\", self.no_intervention_forecast)\n",
    "        # Return the initial state of the new episode\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        # Check if the action is allowed based on the resource limitations\n",
    "        if action == 1 and self.plowing_count >= 2:  # P`lowing limit reached\n",
    "            reward = -1000  # Force 'no action'\n",
    "        elif action == 3 and self.salting_count >= 1:  # Salting limit reached\n",
    "            reward = -1000  # Force 'no action'\n",
    "        elif action == 2:  # Plowing and salting\n",
    "            if self.plowing_count >= 2 or self.salting_count >= 1:\n",
    "                reward = -1000  # If either limit is reached, force 'no action'\n",
    "\n",
    "    \n",
    "        # Update action counters\n",
    "        if action == 1:  # Plowing\n",
    "            self.plowing_count += 1\n",
    "        elif action == 3:  # Salting\n",
    "            self.salting_count += 1\n",
    "        elif action == 2:  # Plowing and salting\n",
    "            self.plowing_count += 1\n",
    "            self.salting_count += 1\n",
    "        # Apply the chosen action to the environment and update the state\n",
    "        # print (\"action\", action)\n",
    "        water, salt, ice, snow = self._apply_action(action)\n",
    "        # print (\" water, salt, ice, snow\", water, salt, ice, snow)\n",
    "        # Update the current state with the new values\n",
    "        self.current_state['initial_Snow'] = snow\n",
    "        self.current_state['initial_water'] = water\n",
    "        self.current_state['initial_Salt'] = salt\n",
    "        self.current_state['initial_ice'] = ice\n",
    "\n",
    "        # Calculate the reward\n",
    "        reward += self._calculate_reward(action, ice, snow)\n",
    "        # print (\"reward\",reward)\n",
    "        # Move to the next row in the dataset, simulating time progression\n",
    "        \n",
    "        # Dynamically determine if it's the last state in the episode\n",
    "        current_episode_index = self.dataset.index.get_loc(self.current_state.name)\n",
    "        episode_start_index = current_episode_index - (current_episode_index % 10)  # Assuming episodes start at indices 0, 10, 20, ...\n",
    "        next_index = current_episode_index + 1\n",
    "        is_last_state_in_episode = (next_index % 10 == 0) or (next_index >= len(self.dataset))\n",
    "        \n",
    "        if is_last_state_in_episode:\n",
    "            done = True\n",
    "        else:\n",
    "            self.current_state = self.dataset.iloc[next_index].copy()\n",
    "            done = False\n",
    "    \n",
    "        return self._get_state(), reward, done\n",
    "\n",
    "    def _get_state(self):\n",
    "        # Extract the current state from the dataset row\n",
    "        current_state_values = [self.current_state[col] for col in ['Air TemperatureC', 'Surface TemperatureC', \n",
    "                                                                     'Wind Speed (act)m/s', 'Precipitation Intensitym/3h', \n",
    "                                                                     'initial_Snow', 'initial_water', 'initial_Salt', 'initial_ice']]\n",
    "        \n",
    "        # Prepare no intervention forecast data for the entire episode\n",
    "        # Assuming no_intervention_forecast is a list of tuples for the entire episode at this point\n",
    "        no_intervention_forecast_flat = [value for forecast in self.no_intervention_forecast for value in forecast]\n",
    "    \n",
    "        # Combine the current state values with the no intervention forecast\n",
    "        # Here, we ensure the state_with_forecast includes the no intervention data for the entire episode\n",
    "        state_with_forecast = np.array(current_state_values + no_intervention_forecast_flat)\n",
    "        # print (\"state_with_forecast\", state_with_forecast)\n",
    "        return state_with_forecast\n",
    "\n",
    "    def _apply_action(self, action):\n",
    "        # Apply the chosen action and update the road conditions\n",
    "        # For simplicity, this function assumes the existence of a function named 'Matrial_on_the_road'\n",
    "        # that calculates the final amounts of water, salt, ice, and snow\n",
    "\n",
    "        air_temp = self.current_state['Air TemperatureC']\n",
    "        surface_temp = self.current_state['Surface TemperatureC']\n",
    "        precipitation = self.current_state['Precipitation Intensitym/3h']\n",
    "        wind_vel = self.current_state['Wind Speed (act)m/s']\n",
    "        initial_snow = self.current_state['initial_Snow']\n",
    "        initial_water = self.current_state['initial_water']\n",
    "        initial_salt = self.current_state['initial_Salt']\n",
    "        initial_ice = self.current_state['initial_ice']\n",
    "        plowing  = 0\n",
    "        if action == 1 or action == 2:  # Plowing or Plowing and Salting\n",
    "            plowing  = 1\n",
    "            \n",
    "\n",
    "        if action == 2 or action == 3:  # Salting or Plowing and Salting\n",
    "            # Measuring salt amount based on the Ruled-Base model\n",
    "                Salt_amount = -32.027 * surface_temp + 79.24\n",
    "                if Salt_amount < 0: Salt_amount = 0\n",
    "                if Salt_amount > 400: Salt_amount = 400  # here salt unit is lb/mile/lane\n",
    "                initial_salt += Salt_amount  # Assuming a constant amount of salt is used\n",
    "\n",
    "        water_final, salt_final, ice_final, snow_final = Matrial_on_the_road(\n",
    "            air_temp, surface_temp, precipitation, wind_vel,\n",
    "            initial_snow, initial_water, initial_salt, initial_ice , plowing\n",
    "        )\n",
    "        # print (f\"action {action}, water_final {water_final}, salt_final {salt_final}, ice_final {ice_final}, snow_final {snow_final}\" )\n",
    "        return water_final, salt_final, ice_final, snow_final\n",
    "\n",
    "    def _calculate_reward(self, action, ice, snow):\n",
    "        # Calculate the reward based on the reduction of ice and snow, and the cost of the action\n",
    "        cost = self.action_costs[action]\n",
    "        # Assuming a penalty of 20 pizoo for each cm of ice or snow\n",
    "        penalty = (ice + snow) * 2000 \n",
    "        reward = -penalty - cost\n",
    "        \n",
    "        return reward\n",
    "\n",
    "print (\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:44:52.138665500Z",
     "start_time": "2024-02-11T15:44:52.024341600Z"
    }
   },
   "id": "7cb48c70a0c1de1b",
   "execution_count": 315
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Assuming the DQNAgent and RoadEnv classes are defined as in your previous code\n",
    "\n",
    "# Load and preprocess dataset\n",
    "file_path = 'Modified_DataSetV8_ConvertedUnits.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "for col in ['initial_Snow', 'initial_water', 'initial_Salt', 'initial_ice']:\n",
    "    if col not in dataset.columns:\n",
    "        dataset[col] = 0\n",
    "\n",
    "# Initialize environment and agent\n",
    "env = RoadEnv(dataset)\n",
    "\n",
    "action_size = 4\n",
    "no_intervention_data_size = 10 * 4  # 10 future states * 4 variables per state\n",
    "current_state_size = 8  # Current state variables\n",
    "total_state_size = current_state_size + no_intervention_data_size\n",
    "\n",
    "agent = DQNAgent(total_state_size, action_size)\n",
    "\n",
    "\n",
    "# Split dataset into training and validation\n",
    "unique_window_ids = dataset['Window_ID'].unique()\n",
    "total_training_windows = len(unique_window_ids)\n",
    "print(f\"Total training window IDs: {total_training_windows}\")\n",
    "\n",
    "# Use only the first 100 episodes for training, excluding the last 10 for validation\n",
    "train_window_ids = unique_window_ids[:4500]  # Adjusted to use only the first 100 episodes\n",
    "validation_window_ids = unique_window_ids[-10:]  # Last 10 for validation\n",
    "\n",
    "Current_training_windows = len(train_window_ids)\n",
    "print(f\"Current training window IDs: {Current_training_windows}\")\n",
    "\n",
    "# Training\n",
    "batch_size = 8\n",
    "\n",
    "def run_episode_simulation(agent, current_episode_data, state_size, episode_num):\n",
    "    best_trial_reward = -np.inf\n",
    "    best_trial_data = None\n",
    "\n",
    "    # Initial simulation setup\n",
    "    for trial in range(N_TRIALS):\n",
    "        # print(f\"Trial {trial}\")\n",
    "        trial_data = {'states': [], 'actions': [], 'rewards': [], 'next_states': [], 'dones': []}\n",
    "        state = env.reset(episode_num)\n",
    "        # print (\"state\",state)\n",
    "        cumulative_reward = 0\n",
    "        # print (\"current_episode_data\",current_episode_data)\n",
    "        for index, row in current_episode_data.iterrows():\n",
    "            state = np.reshape(state, [1, total_state_size])\n",
    "            # print (\"state\", state)\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            # print (\"next_state\",next_state)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            # Save trial data\n",
    "            trial_data['states'].append(state)\n",
    "            trial_data['actions'].append(action)\n",
    "            trial_data['rewards'].append(reward)\n",
    "            trial_data['next_states'].append(next_state)\n",
    "            trial_data['dones'].append(done)\n",
    "            \n",
    "            state = next_state\n",
    "            cumulative_reward += reward\n",
    "\n",
    "            if cumulative_reward > best_trial_reward:\n",
    "                best_trial_reward = cumulative_reward\n",
    "                best_trial_data = trial_data\n",
    "        # print (\"best_trial_data\", best_trial_data)\n",
    "    return best_trial_data\n",
    "\n",
    "N_TRIALS = 100  # Number of trials to run for each episode\n",
    "\n",
    "for i, window_id in enumerate(train_window_ids):\n",
    "    print(f\"****************************************Processing Window ID {window_id} ({i+1}/{Current_training_windows})\")\n",
    "    current_episode_data = dataset[dataset['Window_ID'] == window_id]\n",
    "    # print (\"current_episode_data\", current_episode_data)\n",
    "    # Run episode simulation and get the best trial data\n",
    "    # print (\"iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\", i)\n",
    "    best_trial_data = run_episode_simulation(agent, current_episode_data, total_state_size, episode_num = i)\n",
    "    # print (\"best_trial_data\")\n",
    "    # print (\"best_trial_data['states']\", best_trial_data['states'])\n",
    "    # print (\"best_trial_data['actions']\", best_trial_data['actions'])\n",
    "    # print (\"best_trial_data['rewards']\", best_trial_data['rewards'])\n",
    "    # print (\"best_trial_data['next_states']\",best_trial_data['next_states'])\n",
    "    # print (\"best_trial_data['dones']\", best_trial_data['dones'])\n",
    "    # Store the best trial's outcomes in memory\n",
    "    for state, action, reward, next_state, done in zip(best_trial_data['states'], best_trial_data['actions'], best_trial_data['rewards'], best_trial_data['next_states'], best_trial_data['dones']):\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "    print (\"len(agent.memory)\", len(agent.memory), \"batch_size\", batch_size)\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "agent.model.save('dqn_road_maintenance_model4500.h5')\n",
    "\n",
    "print (\"Training complete\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "642adbaef044a0f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Validation...\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_990\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_991\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_992\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_993\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_994\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_995\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_996\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_997\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_998\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_999\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Cumulative Reward: -3931.2\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n"
     ]
    }
   ],
   "source": [
    "# Validation 11111111111111111111111111111111111\n",
    "# Validation\n",
    "print(\"Starting Validation...\")\n",
    "for window_id in validation_window_ids:\n",
    "    current_episode_data = dataset[dataset['Window_ID'] == window_id]\n",
    "    state = env.reset()  # Reset environment and action counters\n",
    "    episode_actions = []\n",
    "    episode_info = []\n",
    "    cumulative_reward = 0\n",
    "\n",
    "    for index, row in current_episode_data.iterrows():\n",
    "        state = np.reshape(state, [1, total_state_size])\n",
    "        \n",
    "        # Use predict_action to exploit the learned policy\n",
    "        action = agent.predict_action(state)\n",
    "        \n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, total_state_size])\n",
    "        cumulative_reward += reward\n",
    "\n",
    "        episode_actions.append(action)\n",
    "        episode_info.append({\n",
    "            'state': state.flatten().tolist(),\n",
    "            'action': action,\n",
    "            'reward': reward,\n",
    "            'next_state': next_state.flatten().tolist(),\n",
    "            'cumulative_reward': cumulative_reward,\n",
    "            'done': done\n",
    "        })\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nEpisode for Window ID: {window_id}\")\n",
    "    print(\"Actions taken:\", episode_actions)\n",
    "    print(\"Cumulative Reward:\", cumulative_reward)\n",
    "    for info in episode_info:\n",
    "        print(info)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T21:54:13.156503500Z",
     "start_time": "2024-02-07T21:53:58.499920100Z"
    }
   },
   "id": "8ea1b41ab43e0f22",
   "execution_count": 301
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Training 5000-10000\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Assuming the DQNAgent and RoadEnv classes are defined as in your previous code\n",
    "\n",
    "\n",
    "action_size = 4\n",
    "no_intervention_data_size = 10 * 4  # 10 future states * 4 variables per state\n",
    "current_state_size = 8  # Current state variables\n",
    "total_state_size = current_state_size + no_intervention_data_size\n",
    "\n",
    "agent = DQNAgent(total_state_size, action_size, model_path='dqn_road_maintenance_model5000.h5')\n",
    "\n",
    "\n",
    "# Split dataset into training and validation\n",
    "unique_window_ids = dataset['Window_ID'].unique()\n",
    "total_training_windows = len(unique_window_ids)\n",
    "print(f\"Total training window IDs: {total_training_windows}\")\n",
    "\n",
    "# Use only the first 100 episodes for training, excluding the last 10 for validation\n",
    "train_window_ids = unique_window_ids[5000:10000]  # Adjusted to use only the first 100 episodes\n",
    "validation_window_ids = unique_window_ids[-10:]  # Last 10 for validation\n",
    "\n",
    "Current_training_windows = len(train_window_ids)\n",
    "print(f\"Current training window IDs: {Current_training_windows}\")\n",
    "\n",
    "# Training\n",
    "batch_size = 8\n",
    "\n",
    "def run_episode_simulation(agent, current_episode_data, total_state_size, episode_num):\n",
    "    best_trial_reward = -np.inf\n",
    "    best_trial_data = None\n",
    "\n",
    "    # Initial simulation setup\n",
    "    for trial in range(N_TRIALS):\n",
    "        # print(f\"Trial {trial}\")\n",
    "        trial_data = {'states': [], 'actions': [], 'rewards': [], 'next_states': [], 'dones': []}\n",
    "        state = env.reset(episode_num)\n",
    "        # print (\"state\",state)\n",
    "        cumulative_reward = 0\n",
    "        # print (\"current_episode_data\",current_episode_data)\n",
    "        for index, row in current_episode_data.iterrows():\n",
    "            state = np.reshape(state, [1, total_state_size])\n",
    "            # print (\"state\", state)\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            # print (\"next_state\",next_state)\n",
    "            next_state = np.reshape(next_state, [1, total_state_size])\n",
    "\n",
    "            # Save trial data\n",
    "            trial_data['states'].append(state)\n",
    "            trial_data['actions'].append(action)\n",
    "            trial_data['rewards'].append(reward)\n",
    "            trial_data['next_states'].append(next_state)\n",
    "            trial_data['dones'].append(done)\n",
    "            \n",
    "            state = next_state\n",
    "            cumulative_reward += reward\n",
    "\n",
    "            if cumulative_reward > best_trial_reward:\n",
    "                best_trial_reward = cumulative_reward\n",
    "                best_trial_data = trial_data\n",
    "        # print (\"best_trial_data\", best_trial_data)\n",
    "    return best_trial_data\n",
    "\n",
    "N_TRIALS = 5  # Number of trials to run for each episode\n",
    "\n",
    "for i, window_id in enumerate(train_window_ids):\n",
    "    print(f\"****************************************Processing Window ID {window_id} ({i+1}/{Current_training_windows})\")\n",
    "    current_episode_data = dataset[dataset['Window_ID'] == window_id]\n",
    "    # print (\"current_episode_data\", current_episode_data)\n",
    "    # Run episode simulation and get the best trial data\n",
    "    # print (\"iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\", i)\n",
    "    best_trial_data = run_episode_simulation(agent, current_episode_data, total_state_size, episode_num = i)\n",
    "    # print (\"best_trial_data\")\n",
    "    # print (\"best_trial_data['states']\", best_trial_data['states'])\n",
    "    # print (\"best_trial_data['actions']\", best_trial_data['actions'])\n",
    "    # print (\"best_trial_data['rewards']\", best_trial_data['rewards'])\n",
    "    # print (\"best_trial_data['next_states']\",best_trial_data['next_states'])\n",
    "    # print (\"best_trial_data['dones']\", best_trial_data['dones'])\n",
    "    # Store the best trial's outcomes in memory\n",
    "    for state, action, reward, next_state, done in zip(best_trial_data['states'], best_trial_data['actions'], best_trial_data['rewards'], best_trial_data['next_states'], best_trial_data['dones']):\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "agent.model.save('dqn_road_maintenance_model10000.h5')\n",
    "\n",
    "print (\"Training complete\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9b822f94d02a90",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Validation 222222222222222222222222222222222222222222\n",
    "print(\"Starting Validation 2\")\n",
    "for window_id in validation_window_ids:\n",
    "    current_episode_data = dataset[dataset['Window_ID'] == window_id]\n",
    "    state = env.reset()  # Ensure this resets both the state and action counters\n",
    "    episode_actions = []\n",
    "    episode_info = []\n",
    "    cumulative_reward = 0\n",
    "    for index, row in current_episode_data.iterrows():\n",
    "        state = np.reshape(state, [1, total_state_size])\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        # Get the next state, reward, and whether the episode is done, considering action restrictions\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, total_state_size])\n",
    "        cumulative_reward += reward\n",
    "        # Store action and state info\n",
    "        episode_actions.append(action)\n",
    "        episode_info.append({\n",
    "            'state': state.flatten().tolist(),\n",
    "            'action': action,\n",
    "            'reward': reward,\n",
    "            'next_state': next_state.flatten().tolist(),\n",
    "            'cumulative_reward': cumulative_reward,\n",
    "            'done': done\n",
    "        })\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Print episode information\n",
    "    print(f\"\\nEpisode for Window ID: {window_id}\")\n",
    "    print(\"Actions taken:\", episode_actions)\n",
    "    for info in episode_info:\n",
    "        print(info)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ae6eb709716e352",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Training 5000-10000\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Assuming the DQNAgent and RoadEnv classes are defined as in your previous code\n",
    "\n",
    "\n",
    "action_size = 4\n",
    "no_intervention_data_size = 10 * 4  # 10 future states * 4 variables per state\n",
    "current_state_size = 8  # Current state variables\n",
    "total_state_size = current_state_size + no_intervention_data_size\n",
    "\n",
    "agent = DQNAgent(total_state_size, action_size, model_path='dqn_road_maintenance_model10000.h5')\n",
    "\n",
    "\n",
    "# Split dataset into training and validation\n",
    "unique_window_ids = dataset['Window_ID'].unique()\n",
    "total_training_windows = len(unique_window_ids)\n",
    "print(f\"Total training window IDs: {total_training_windows}\")\n",
    "\n",
    "# Use only the first 100 episodes for training, excluding the last 10 for validation\n",
    "train_window_ids = unique_window_ids[10000:20000]  # Adjusted to use only the first 100 episodes\n",
    "validation_window_ids = unique_window_ids[-10:]  # Last 10 for validation\n",
    "\n",
    "Current_training_windows = len(train_window_ids)\n",
    "print(f\"Current training window IDs: {Current_training_windows}\")\n",
    "\n",
    "# Training\n",
    "batch_size = 8\n",
    "N_TRIALS = 100\n",
    "\n",
    "def run_episode_simulation(agent, current_episode_data, total_state_size, episode_num):\n",
    "    best_trial_reward = -np.inf\n",
    "    best_trial_data = None\n",
    "\n",
    "    # Initial simulation setup\n",
    "    for trial in range(N_TRIALS):\n",
    "        # print(f\"Trial {trial}\")\n",
    "        trial_data = {'states': [], 'actions': [], 'rewards': [], 'next_states': [], 'dones': []}\n",
    "        state = env.reset(episode_num)\n",
    "        # print (\"state\",state)\n",
    "        cumulative_reward = 0\n",
    "        # print (\"current_episode_data\",current_episode_data)\n",
    "        for index, row in current_episode_data.iterrows():\n",
    "            state = np.reshape(state, [1, total_state_size])\n",
    "            # print (\"state\", state)\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            # print (\"next_state\",next_state)\n",
    "            next_state = np.reshape(next_state, [1, total_state_size])\n",
    "\n",
    "            # Save trial data\n",
    "            trial_data['states'].append(state)\n",
    "            trial_data['actions'].append(action)\n",
    "            trial_data['rewards'].append(reward)\n",
    "            trial_data['next_states'].append(next_state)\n",
    "            trial_data['dones'].append(done)\n",
    "            \n",
    "            state = next_state\n",
    "            cumulative_reward += reward\n",
    "\n",
    "            if cumulative_reward > best_trial_reward:\n",
    "                best_trial_reward = cumulative_reward\n",
    "                best_trial_data = trial_data\n",
    "        # print (\"best_trial_data\", best_trial_data)\n",
    "    return best_trial_data\n",
    "# Define constants\n",
    "EPISODES_BEFORE_REPLAY = 5  # Number of episodes before replaying experiences\n",
    "REPLAY_BATCH_SIZE = 8  # Batch size for replay\n",
    "  # Number of trials to run for each episode\n",
    "\n",
    "# Training loop\n",
    "for i, window_id in enumerate(train_window_ids):\n",
    "    print(f\"****************************************Processing Window ID {window_id} ({i+1}/{Current_training_windows})\")\n",
    "    current_episode_data = dataset[dataset['Window_ID'] == window_id]\n",
    "\n",
    "    # Run episode simulation and get the best trial data\n",
    "    best_trial_data = run_episode_simulation(agent, current_episode_data, total_state_size, episode_num=i)\n",
    "    \n",
    "    # Store the best trial's outcomes in memory\n",
    "    for state, action, reward, next_state, done in zip(best_trial_data['states'], best_trial_data['actions'], best_trial_data['rewards'], best_trial_data['next_states'], best_trial_data['dones']):\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "    # Check if it's time for replay\n",
    "    if (i + 1) % EPISODES_BEFORE_REPLAY == 0:\n",
    "        # Replay experiences\n",
    "        for _ in range(REPLAY_BATCH_SIZE):\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(REPLAY_BATCH_SIZE)\n",
    "\n",
    "# Save the trained model\n",
    "agent.model.save('dqn_road_maintenance_model20000.h5')\n",
    "\n",
    "print(\"Training complete\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cde9cc08a4d1fe99",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Validation 3\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_990\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_991\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_992\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_993\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_994\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_995\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_996\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_997\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_998\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -457.2, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3839.3999999999996, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3931.2, 'done': True}\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "\n",
      "Episode for Window ID: Tipler_window_999\n",
      "Actions taken: [0, 0, 0, 0, 0, 0, 0, 0, 3, 0]\n",
      "{'state': [-11.58, -11.06, 2.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.65, -10.8, 2.92, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.4, 0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.59, -10.27, 2.42, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': 0.0, 'next_state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': 0.0, 'done': False}\n",
      "{'state': [-9.58, -10.4, 2.9, 0.00381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -685.8000000000001, 'next_state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -685.8000000000001, 'done': False}\n",
      "{'state': [-8.51, -6.19, 5.11, 0.00508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -914.4, 'next_state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -1600.2, 'done': False}\n",
      "{'state': [-7.01, -3.08, 4.78, 0.00584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -1051.1999999999998, 'next_state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -2651.3999999999996, 'done': False}\n",
      "{'state': [-6.41, -7.2, 1.54, 0.00406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -730.8000000000001, 'next_state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3382.2, 'done': False}\n",
      "{'state': [-7.64, -9.05, 1.6, 0.00254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 3, 'reward': -5.0, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3387.2, 'done': False}\n",
      "{'state': [-8.54, -9.75, 1.34, 0.00051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'action': 0, 'reward': -91.80000000000001, 'next_state': [-8.54, -9.75, 1.34, 0.00051, 0.0459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34290000000000004, 0.0, 0.0, 0.03429000000000001, 0.8001, 0.0, 0.0, 0.11430000000000001, 1.3256999999999999, 0.0, 0.0, 0.24687, 1.6911, 0.0, 0.0, 0.41598, 1.9197, 0.0, 0.0, 0.60795, 1.9656], 'cumulative_reward': -3479.0, 'done': True}\n"
     ]
    }
   ],
   "source": [
    "# Validation 33333333333333333333333333333333333333\n",
    "print(\"Starting Validation 3\")\n",
    "for window_id in validation_window_ids:\n",
    "    current_episode_data = dataset[dataset['Window_ID'] == window_id]\n",
    "    state = env.reset()  # Ensure this resets both the state and action counters\n",
    "    episode_actions = []\n",
    "    episode_info = []\n",
    "    cumulative_reward = 0\n",
    "    for index, row in current_episode_data.iterrows():\n",
    "        state = np.reshape(state, [1, total_state_size])\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        # Get the next state, reward, and whether the episode is done, considering action restrictions\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, total_state_size])\n",
    "        cumulative_reward += reward\n",
    "        # Store action and state info\n",
    "        episode_actions.append(action)\n",
    "        episode_info.append({\n",
    "            'state': state.flatten().tolist(),\n",
    "            'action': action,\n",
    "            'reward': reward,\n",
    "            'next_state': next_state.flatten().tolist(),\n",
    "            'cumulative_reward': cumulative_reward,\n",
    "            'done': done\n",
    "        })\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Print episode information\n",
    "    print(f\"\\nEpisode for Window ID: {window_id}\")\n",
    "    print(\"Actions taken:\", episode_actions)\n",
    "    for info in episode_info:\n",
    "        print(info)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T14:57:06.022396Z",
     "start_time": "2024-02-10T14:56:48.952126Z"
    }
   },
   "id": "86bd17fce0b8a701",
   "execution_count": 305
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Training 5000-10000\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Assuming the DQNAgent and RoadEnv classes are defined as in your previous code\n",
    "\n",
    "\n",
    "action_size = 4\n",
    "no_intervention_data_size = 10 * 4  # 10 future states * 4 variables per state\n",
    "current_state_size = 8  # Current state variables\n",
    "total_state_size = current_state_size + no_intervention_data_size\n",
    "\n",
    "agent = DQNAgent(total_state_size, action_size, model_path='dqn_road_maintenance_model20000.h5')\n",
    "\n",
    "\n",
    "# Split dataset into training and validation\n",
    "unique_window_ids = dataset['Window_ID'].unique()\n",
    "total_training_windows = len(unique_window_ids)\n",
    "print(f\"Total training window IDs: {total_training_windows}\")\n",
    "\n",
    "# Use only the first 100 episodes for training, excluding the last 10 for validation\n",
    "train_window_ids = unique_window_ids[20000:30000]  # Adjusted to use only the first 100 episodes\n",
    "validation_window_ids = unique_window_ids[-10:]  # Last 10 for validation\n",
    "\n",
    "Current_training_windows = len(train_window_ids)\n",
    "print(f\"Current training window IDs: {Current_training_windows}\")\n",
    "\n",
    "# Training\n",
    "batch_size = 8\n",
    "\n",
    "def run_episode_simulation(agent, current_episode_data, total_state_size, episode_num):\n",
    "    best_trial_reward = -np.inf\n",
    "    best_trial_data = None\n",
    "\n",
    "    # Initial simulation setup\n",
    "    for trial in range(N_TRIALS):\n",
    "        # print(f\"Trial {trial}\")\n",
    "        trial_data = {'states': [], 'actions': [], 'rewards': [], 'next_states': [], 'dones': []}\n",
    "        state = env.reset(episode_num)\n",
    "        # print (\"state\",state)\n",
    "        cumulative_reward = 0\n",
    "        # print (\"current_episode_data\",current_episode_data)\n",
    "        for index, row in current_episode_data.iterrows():\n",
    "            state = np.reshape(state, [1, total_state_size])\n",
    "            # print (\"state\", state)\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            # print (\"next_state\",next_state)\n",
    "            next_state = np.reshape(next_state, [1, total_state_size])\n",
    "\n",
    "            # Save trial data\n",
    "            trial_data['states'].append(state)\n",
    "            trial_data['actions'].append(action)\n",
    "            trial_data['rewards'].append(reward)\n",
    "            trial_data['next_states'].append(next_state)\n",
    "            trial_data['dones'].append(done)\n",
    "            \n",
    "            state = next_state\n",
    "            cumulative_reward += reward\n",
    "\n",
    "            if cumulative_reward > best_trial_reward:\n",
    "                best_trial_reward = cumulative_reward\n",
    "                best_trial_data = trial_data\n",
    "        # print (\"best_trial_data\", best_trial_data)\n",
    "    return best_trial_data\n",
    "\n",
    "N_TRIALS = 30  # Number of trials to run for each episode\n",
    "\n",
    "for i, window_id in enumerate(train_window_ids):\n",
    "    print(f\"****************************************Processing Window ID {window_id} ({i+1}/{Current_training_windows})\")\n",
    "    current_episode_data = dataset[dataset['Window_ID'] == window_id]\n",
    "    # print (\"current_episode_data\", current_episode_data)\n",
    "    # Run episode simulation and get the best trial data\n",
    "    # print (\"iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\", i)\n",
    "    best_trial_data = run_episode_simulation(agent, current_episode_data, total_state_size, episode_num = i)\n",
    "    # print (\"best_trial_data\")\n",
    "    # print (\"best_trial_data['states']\", best_trial_data['states'])\n",
    "    # print (\"best_trial_data['actions']\", best_trial_data['actions'])\n",
    "    # print (\"best_trial_data['rewards']\", best_trial_data['rewards'])\n",
    "    # print (\"best_trial_data['next_states']\",best_trial_data['next_states'])\n",
    "    # print (\"best_trial_data['dones']\", best_trial_data['dones'])\n",
    "    # Store the best trial's outcomes in memory\n",
    "    for state, action, reward, next_state, done in zip(best_trial_data['states'], best_trial_data['actions'], best_trial_data['rewards'], best_trial_data['next_states'], best_trial_data['dones']):\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "agent.model.save('dqn_road_maintenance_model30000.h5')\n",
    "\n",
    "print (\"Training complete\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c970cc7f7a4099e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d2bfe81d9f3fdda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
